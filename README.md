# 100 D√≠as de IA

| Libros y Recursos | Estado de Finalizaci√≥n |
| ----- | -----|
| 1. [**Machine Learning Specialization**](https://www.coursera.org/specializations/machine-learning-introduction?page=1) | ‚úÖ |
| 2. [**Deep Learning Specialization**](https://www.coursera.org/specializations/deep-learning?)| ‚úÖ  |
| 3. [**IA generativa con grandes modelos ling√º√≠sticos**](https://www.coursera.org/learn/generative-ai-with-llms/) | ‚úÖ |
| 4. [**Curso de Deep Learning**](https://youtube.com/playlist?list=PLcfxtMhW8iFNMTFKrYMYYzVTNzu-xG-Ys&si=lqAlbDIhtOJ5zMP8) | ‚úÖ |
| 5. [**Computer Vision**](https://youtube.com/playlist?list=PLISuMnTdVU-yvm6X7SwKtUosfr4ZarStU&si=FOMUjJ5SvotgMhHW) | ‚úÖ |

| Proyectos Completados |
| ----------------- |
| 1.  |
| 2.  |
| 3. ... |

# Temas Aprendidos en Cada D√≠a
| **D√≠as** | **Temas Cubiertos** | 
|--------- | ------------------ |
| [D√≠a1](#D√≠a1) | Introducci√≥n a Deep Learning | 
| [D√≠a2](#D√≠a2) | Historia y Evoluci√≥n de Deep Learning | 
| [D√≠a3](#D√≠a3) | Breve Descripci√≥n de las Diferentes T√©cnicas en Deep Learning | 
| [D√≠a4](#D√≠a4) | Comparaci√≥n y Aplicaciones de T√©cnicas de Deep Learning en el Mundo Real | 
| [D√≠a5](#D√≠a5) | Redes Neuronales Artificiales (ANNs) | 
| [D√≠a6](#D√≠a6) | Forward y Backward Propagation | 
| [D√≠a7](#D√≠a7) | Coste y Funciones de P√©rdida | 
| [D√≠a8](#D√≠a8) | Algoritmos de Optimizaci√≥n | 
| [D√≠a9](#D√≠a9) | Overfitting y T√©cnicas de Regularizaci√≥n | 
| [D√≠a10](#D√≠a10) | Construyendo una Red Neuronal desde Cero: Clasificaci√≥n de Flores Iris | 
| [D√≠a11](#D√≠a11) |  | 
| [D√≠a12](#D√≠a12) |  | 
| [D√≠a13](#D√≠a13) |  | 
| [D√≠a14](#D√≠a14) |  | 
| [D√≠a15](#D√≠a15) |  | 
| [D√≠a16](#D√≠a16) |  | 
| [D√≠a17](#D√≠a17) |  | 
| [D√≠a18](#D√≠a18) |  | 
| [D√≠a19](#D√≠a19) |  | 
| [D√≠a20](#D√≠a20) |  | 
| [D√≠a21](#D√≠a21) |  | 
| [D√≠a22](#D√≠a22) |  | 
| [D√≠a23](#D√≠a23) |  | 
| [D√≠a24](#D√≠a24) |  | 
| [D√≠a25](#D√≠a25) |  | 
| [D√≠a26](#D√≠a26) |  | 
| [D√≠a27](#D√≠a27) |  | 
| [D√≠a28](#D√≠a28) |  | 
| [D√≠a29](#D√≠a29) |  | 
| [D√≠a30](#D√≠a30) |  | 
| [D√≠a31](#D√≠a31) |  | 
| [D√≠a32](#D√≠a32) |  | 
| [D√≠a33](#D√≠a33) |  | 
| [D√≠a34](#D√≠a34) |  | 
| [D√≠a35](#D√≠a35) |  | 
| [D√≠a36](#D√≠a36) |  | 
| [D√≠a37](#D√≠a37) |  | 
| [D√≠a38](#D√≠a38) |  | 
| [D√≠a39](#D√≠a39) |  | 
| [D√≠a40](#D√≠a40) |  | 
| [D√≠a41](#D√≠a41) |  | 
| [D√≠a42](#D√≠a42) |  | 
| [D√≠a43](#D√≠a43) |  | 
| [D√≠a44](#D√≠a44) |  | 
| [D√≠a45](#D√≠a45) |  | 
| [D√≠a46](#D√≠a46) |  | 
| [D√≠a47](#D√≠a47) |  | 
| [D√≠a48](#D√≠a48) |  | 
| [D√≠a49](#D√≠a49) |  | 
| [D√≠a50](#D√≠a50) |  | 
| [D√≠a51](#D√≠a51) |  | 
| [D√≠a52](#D√≠a52) |  | 
| [D√≠a53](#D√≠a53) |  | 
| [D√≠a54](#D√≠a54) |  | 
| [D√≠a55](#D√≠a55) |  | 
| [D√≠a56](#D√≠a56) |  | 
| [D√≠a57](#D√≠a57) |  | 
| [D√≠a58](#D√≠a58) |  | 
| [D√≠a59](#D√≠a59) |  | 
| [D√≠a60](#D√≠a60) |  | 
| [D√≠a61](#D√≠a61) |  | 
| [D√≠a62](#D√≠a62) |  | 
| [D√≠a63](#D√≠a63) |  | 
| [D√≠a64](#D√≠a64) |  | 
| [D√≠a65](#D√≠a65) |  | 
| [D√≠a66](#D√≠a66) |  | 
| [D√≠a67](#D√≠a67) |  | 
| [D√≠a68](#D√≠a68) |  | 
| [D√≠a69](#D√≠a69) |  | 
| [D√≠a70](#D√≠a70) |  | 
| [D√≠a71](#D√≠a71) |  | 
| [D√≠a72](#D√≠a72) |  | 
| [D√≠a73](#D√≠a73) |  | 
| [D√≠a74](#D√≠a74) |  | 
| [D√≠a75](#D√≠a75) |  | 
| [D√≠a76](#D√≠a76) |  | 
| [D√≠a77](#D√≠a77) |  | 
| [D√≠a78](#D√≠a78) |  | 
| [D√≠a79](#D√≠a79) |  | 
| [D√≠a80](#D√≠a80) |  | 
| [D√≠a81](#D√≠a81) |  | 
| [D√≠a82](#D√≠a82) |  | 
| [D√≠a83](#D√≠a83) |  | 
| [D√≠a84](#D√≠a84) |  | 
| [D√≠a85](#D√≠a85) |  | 
| [D√≠a86](#D√≠a86) |  | 
| [D√≠a87](#D√≠a87) |  | 
| [D√≠a88](#D√≠a88) |  | 
| [D√≠a89](#D√≠a89) |  | 
| [D√≠a90](#D√≠a90) |  | 
| [D√≠a91](#D√≠a91) |  | 
| [D√≠a92](#D√≠a92) |  | 
| [D√≠a93](#D√≠a93) |  | 
| [D√≠a94](#D√≠a94) |  | 
| [D√≠a95](#D√≠a95) |  | 
| [D√≠a96](#D√≠a96) |  | 
| [D√≠a97](#D√≠a97) |  | 
| [D√≠a98](#D√≠a98) |  | 
| [D√≠a99](#D√≠a99) |  | 
| [D√≠a100](#D√≠a100) |  | 

# D√≠a1
---
## Introducci√≥n a Deep Learning üåü

¬°Bienvenidos al primer d√≠a de mi viaje de 100 d√≠as explorando la Inteligencia Artificial! üöÄ Hoy comenzamos con **Deep Learning**.

### ¬øQu√© es Deep Learning?

Deep Learning, o Aprendizaje Profundo, es una rama avanzada del **Machine Learning** que se inspira en la estructura y funci√≥n del cerebro humano. Utiliza **redes neuronales artificiales** para aprender de grandes vol√∫menes de datos y tomar decisiones o hacer predicciones precisas.

### ¬øPor qu√© es importante?

En los √∫ltimos a√±os, el Deep Learning ha revolucionado muchas industrias. Desde la **visi√≥n por computadora** que permite a los veh√≠culos aut√≥nomos ver el mundo, hasta el **procesamiento de lenguaje natural** que ayuda a las m√°quinas a entender y responder en lenguaje humano. Deep Learning es la tecnolog√≠a detr√°s de innovaciones impresionantes que est√°n cambiando la forma en que interactuamos con el mundo digital.

### ¬øC√≥mo funciona?

Las redes neuronales profundas est√°n compuestas por capas de neuronas artificiales. Cada capa transforma la entrada de datos en algo m√°s √∫til para la siguiente capa. A trav√©s de un proceso de entrenamiento, estas redes aprenden a extraer caracter√≠sticas complejas y patrones directamente de los datos.

### Ejemplos de Aplicaciones de Deep Learning:

- **Reconocimiento de Im√°genes**: Identificar objetos y personas en fotos y videos.
- **Traducci√≥n Autom√°tica**: Convertir texto de un idioma a otro con gran precisi√≥n.
- **Diagn√≥stico M√©dico**: Analizar im√°genes m√©dicas para detectar enfermedades.



 **Recursos para comenzar**üß†:
- **[APRENDIZAJE PROFUNDO EN INTELIGENCIA ARTIFICIAL](https://youtu.be/Zcb8R2TF3bI?si=f1NIEJgXh7cWdadV)** - Una breve esplicacion dew que es deep learning.
- **[¬øQUE ES EL DEEP LEARNING? - EXPLICADO MUY FACIL](https://youtu.be/s0SbvGiG28w?si=Rr51xld8H8ilsrz9)** - Video de Dalto explicando que es deep learning.
- **[¬øQu√© son el MACHINE LEARNING y el DEEP LEARNING?](https://youtu.be/HMEjoBnCc9c?si=U5MXn98cY7Yovy8w)** - Diferencias entre el Machine Learning y el Deep Learning.
- **[¬øDe qu√© es capaz la inteligencia artificial? ](https://youtu.be/34Kz-PP_X7c?si=sbV0ENQYtvT2JKiI)** - Documental de DW.

¬°√önete a m√≠ en este emocionante viaje y no dudes en compartir tus pensamientos y preguntas! üöÄ

---
# D√≠a2
---
## Historia y Evoluci√≥n de Deep Learning üìú

¬°Bienvenidos al segundo d√≠a de nuestra traves√≠a de 100 d√≠as en el mundo de la Inteligencia Artificial! Hoy, exploramos la fascinante **historia y evoluci√≥n de Deep Learning**. üåü

### Or√≠genes y Primeros Pasos

#### 1943: La Idea de una Neurona Artificial üí°
El viaje de Deep Learning comenz√≥ con Warren McCulloch y Walter Pitts, quienes propusieron el primer modelo matem√°tico de una **neurona artificial**. Su trabajo sent√≥ las bases para las redes neuronales, sugiriendo que las neuronas podr√≠an ser el equivalente funcional de un interruptor binario.

#### 1958: El Perceptr√≥n ü§ñ
Frank Rosenblatt desarroll√≥ el **Perceptr√≥n**, el primer modelo de red neuronal capaz de aprender. El perceptr√≥n es un tipo simple de red que puede clasificar datos en dos categor√≠as. Aunque su capacidad era limitada, fue un hito importante que inspir√≥ investigaciones futuras.

### El Invierno de la IA ‚ùÑÔ∏è

#### A√±os 70-80: Desaf√≠os y Dudas
Durante los a√±os 70 y 80, las expectativas sobre las redes neuronales no se cumplieron, y la falta de poder computacional y datos llev√≥ a lo que se conoce como el **"invierno de la IA"**. Durante este per√≠odo, la investigaci√≥n en redes neuronales se desaceler√≥ debido al escepticismo y la falta de avances significativos.

### Renacimiento y Avances üöÄ

#### 1986: El Redescubrimiento de la Propagaci√≥n hacia Atr√°s
En 1986, David Rumelhart, Geoffrey Hinton y Ronald Williams revitalizaron el inter√©s en las redes neuronales con su trabajo sobre la **retropropagaci√≥n**. Este algoritmo permiti√≥ el entrenamiento eficaz de redes neuronales multicapa, allanando el camino para el desarrollo de modelos m√°s complejos.

#### A√±os 90: Aplicaciones Pr√°cticas üåê
A medida que aumentaba el poder computacional y se dispon√≠a de m√°s datos, las redes neuronales comenzaron a mostrar su potencial en √°reas como el reconocimiento de patrones y la predicci√≥n financiera. Sin embargo, a√∫n quedaban desaf√≠os significativos por superar.

### La Era de Deep Learning üí•

#### 2006: El Avance de las Redes Profundas
Geoffrey Hinton y su equipo introdujeron el concepto de **preentrenamiento de capas** en redes profundas, lo que permiti√≥ entrenar eficientemente modelos con muchas capas. Este avance marc√≥ el comienzo de la **era de Deep Learning**, demostrando que las redes neuronales profundas pod√≠an superar a los m√©todos tradicionales en tareas complejas.

#### 2012: El Triunfo en ImageNet üèÜ
El hito crucial lleg√≥ en 2012 cuando una red profunda conocida como **AlexNet**, desarrollada por Alex Krizhevsky, Ilya Sutskever y Geoffrey Hinton, gan√≥ el desaf√≠o de reconocimiento de im√°genes de **ImageNet** con un margen significativo. Esto consolid√≥ a Deep Learning como la tecnolog√≠a l√≠der en visi√≥n por computadora.

### Transformadores y Nuevas Fronteras üöÄ

#### 2017: El Surgimiento de los Transformadores
En 2017, el art√≠culo "Attention is All You Need" de Google introdujo el **modelo Transformer**, revolucionando el procesamiento del lenguaje natural (NLP). Los Transformers, como **BERT** y **GPT**, demostraron capacidades impresionantes en tareas de lenguaje, superando a los modelos anteriores.

#### 2018: GPT y el Avance de los Modelos de Lenguaje
OpenAI lanz√≥ **GPT (Generative Pre-trained Transformer)**, seguido por GPT-2 y el famoso **GPT-3** en 2020. Estos modelos mostraron habilidades sin precedentes en generaci√≥n de texto, comprensi√≥n y traducci√≥n, marcando un hito en el desarrollo de la IA.

### Innovaciones Recientes üîÑ

#### 2021: DALL-E y la Creatividad Artificial
OpenAI present√≥ **DALL-E**, un modelo capaz de generar im√°genes a partir de descripciones textuales. Esta innovaci√≥n destac√≥ la capacidad de la IA para combinar lenguaje y visi√≥n, abriendo nuevas posibilidades en arte y dise√±o.

#### 2021: AlphaFold y la Revoluci√≥n en la Biolog√≠a
DeepMind's **AlphaFold** resolvi√≥ uno de los mayores desaf√≠os en biolog√≠a: la predicci√≥n de estructuras proteicas. Este avance promete acelerar el descubrimiento de medicamentos y mejorar nuestra comprensi√≥n de la biolog√≠a molecular.

#### 2022: ChatGPT y la Conversaci√≥n Natural
OpenAI lanz√≥ **ChatGPT**, una versi√≥n mejorada de GPT-3 optimizada para conversaciones interactivas. Este modelo demostr√≥ habilidades avanzadas en el di√°logo, respondiendo preguntas y asistiendo en diversas tareas de manera coherente y precisa.


### Recursos para Explorar M√°s:

- **[Breve Historia de las Redes Neuronales Artificiales](https://www.aprendemachinelearning.com/breve-historia-de-las-redes-neuronales-artificiales/)** - Un art√≠culo detallado sobre la evoluci√≥n de las redes neuronales.
- **[The brief history of artificial intelligence](https://ourworldindata.org/brief-history-of-ai)** - Un art√≠culo detallado sobre la evoluci√≥n de la IA.

### Evoluci√≥n de los modelos de IA con respecto a la computaci√≥n utilizada en su entrenamiento

<<<<<<< HEAD
=======
https://github.com/Oliver369X/100DaysOfAI/assets/110129950/64c6b46d-4c12-4e7a-8511-b35a2ad5be8e

>>>>>>> 52f223851c1f64cb143e7b84519e39d23a2985f8
---
# D√≠a3
---
## Breve Descripci√≥n de las Diferentes T√©cnicas en Deep Learning üß†


### 1. Redes Neuronales Convolucionales (CNN) üñºÔ∏è

#### Descripci√≥n
Las **Redes Neuronales Convolucionales (CNN)** est√°n dise√±adas para procesar datos con una estructura de grilla, como las im√°genes. Utilizan capas convolucionales que aplican filtros para detectar caracter√≠sticas como bordes, texturas y patrones en las im√°genes.

#### Componentes Clave
- **Capas Convolucionales**: Aplican filtros para extraer caracter√≠sticas locales.
- **Capas de Pooling**: Reducen la dimensionalidad y ayudan a generalizar.
- **Capas Completamente Conectadas**: Usadas para clasificar y tomar decisiones basadas en las caracter√≠sticas extra√≠das.

### 2. Redes Neuronales Recurrentes (RNN) üîÅ

#### Descripci√≥n
Las **Redes Neuronales Recurrentes (RNN)** est√°n dise√±adas para procesar secuencias de datos, como texto o series temporales. Tienen conexiones recurrentes que permiten que la informaci√≥n persista, lo que es √∫til para modelar dependencias temporales.

#### Componentes Clave
- **Celdas Recurrentes**: Mantienen un estado oculto que captura informaci√≥n de pasos anteriores.
- **LSTM y GRU**: Variantes avanzadas de RNN que abordan problemas de memoria a largo plazo.

### 3. Redes Generativas Adversariales (GAN) üé®

#### Descripci√≥n
Las **Redes Generativas Adversariales (GAN)** constan de dos redes: una generadora y una discriminadora. La generadora crea datos falsos, mientras que la discriminadora intenta distinguir entre datos reales y falsos. Este proceso competitivo mejora la capacidad de la generadora para producir datos realistas.

#### Componentes Clave
- **Generador**: Crea datos sint√©ticos.
- **Discriminador**: Distingue entre datos reales y generados.
- **Juego Adversarial**: La competencia entre las dos redes mejora el rendimiento del sistema.

### 4. Transformadores üîÑ

#### Descripci√≥n
Los **Transformadores** han revolucionado el procesamiento del lenguaje natural (NLP) con su mecanismo de atenci√≥n que permite procesar todas las palabras de una oraci√≥n en paralelo. Esto los hace altamente eficientes y precisos en tareas de lenguaje.

#### Componentes Clave
- **Mecanismo de Atenci√≥n**: Pondera la importancia de diferentes palabras en una oraci√≥n.
- **Codificadores y Decodificadores**: Procesan las secuencias de entrada y generan secuencias de salida.

### 5. Modelos de Difusi√≥n üå´Ô∏è

#### Descripci√≥n
Los **Modelos de Difusi√≥n** son una t√©cnica emergente en generaci√≥n de datos. Funcionan modelando la distribuci√≥n de los datos y luego generando nuevos ejemplos a partir de esta distribuci√≥n, similar a los procesos f√≠sicos de difusi√≥n.

#### Componentes Clave
- **Proceso de Difusi√≥n**: Modela c√≥mo los datos cambian con el tiempo.
- **Reconstrucci√≥n Inversa**: Genera nuevos datos a partir del proceso de difusi√≥n.

### 6. Modelos Multimodales üé•üéµüìù

#### Descripci√≥n
Los **Modelos Multimodales** integran y procesan m√∫ltiples tipos de datos, como texto, im√°genes y audio, para realizar tareas complejas que requieren comprensi√≥n de informaci√≥n diversa.

#### Componentes Clave
- **Fusi√≥n de Modalidades**: Combina diferentes tipos de datos en una representaci√≥n unificada.
- **Atenci√≥n Cruzada**: Captura interacciones entre diferentes modalidades.


### Recursos para Explorar M√°s:

- **[¬°Redes Neuronales CONVOLUCIONALES! ](https://youtu.be/V8j1oENVz00?si=RY91rvLjMXPbjRbF)** - Video detallado sobre CNN.
- **[Understanding LSTM Networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)** - Una explicaci√≥n profunda sobre las RNN y LSTM.
- **[GANs in Action](https://www.youtube.com/watch?v=8L11aMN5KY8)** - Un video tutorial sobre GANs.
- **[The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)** - Una gu√≠a visual sobre transformadores.
- **[C√≥mo funciona la generaci√≥n de im√°genes con IA (modelos de difusi√≥n)](https://youtu.be/mNxzQvdVSQI?si=_Lno74MYiqcbidei)** - Introducci√≥n a los modelos de difusi√≥n.
- **[Multimodal learning](https://en.wikipedia.org/wiki/Multimodal_learning)** - Definicion de Wikipedia.

---

# D√≠a4
---
## Comparaci√≥n y Aplicaciones de T√©cnicas de Deep Learning en el Mundo Real üåç

¬°Hola a todos! compararemos las diferentes t√©cnicas de Deep Learning que discutimos ayer y exploraremos sus aplicaciones en el mundo real. Vamos a sumergirnos en c√≥mo se utilizan las **CNN, RNN, GAN, Transformadores, Modelos de Difusi√≥n y Modelos Multimodales** en diversos campos. üåê

### Comparaci√≥n de T√©cnicas de Deep Learning

| T√©cnica         | Descripci√≥n                                                   | Fortalezas                                                     | Limitaciones                                                       |
|-----------------|---------------------------------------------------------------|----------------------------------------------------------------|--------------------------------------------------------------------|
| **CNN**         | Procesan datos con estructura de grilla (como im√°genes).       | Excelente para tareas de visi√≥n por computadora.                | No maneja bien datos secuenciales o dependencias temporales.       |
| **RNN**         | Procesan secuencias de datos (como texto o series temporales). | Capturan dependencias temporales y contextuales.                | Pueden sufrir de problemas de gradiente desaparecido/explosivo.    |
| **GAN**         | Generan datos sint√©ticos mediante una competencia entre dos redes. | Producen datos realistas en imagen, video y audio.              | Dificultad en entrenamiento y estabilidad.                         |
| **Transformadores** | Procesan secuencias de datos en paralelo utilizando atenci√≥n. | Eficientes y precisos en procesamiento de lenguaje natural.     | Requieren grandes cantidades de datos y recursos computacionales.  |
| **Modelos de Difusi√≥n** | Modelan la distribuci√≥n de datos para generaci√≥n.        | Alta calidad en generaci√≥n de im√°genes y datos.                 | T√©cnicamente complejos y requieren mucho tiempo de entrenamiento.  |
| **Modelos Multimodales** | Integran m√∫ltiples tipos de datos (texto, imagen, audio). | Capturan interacciones complejas entre diferentes tipos de datos. | Complejidad en la fusi√≥n de datos y gesti√≥n de m√∫ltiples modalidades. |

### Aplicaciones en el Mundo Real

#### 1. Redes Neuronales Convolucionales (CNN) üñºÔ∏è

**Aplicaciones:**
- **Reconocimiento de Im√°genes**: Identificaci√≥n de objetos, personas y escenas en im√°genes.
- **Diagn√≥stico M√©dico**: An√°lisis de im√°genes m√©dicas, como radiograf√≠as y resonancias magn√©ticas.
- **Seguridad y Vigilancia**: Detecci√≥n de anomal√≠as y reconocimiento facial.

#### 2. Redes Neuronales Recurrentes (RNN) üîÅ

**Aplicaciones:**
- **Procesamiento del Lenguaje Natural (NLP)**: Traducci√≥n autom√°tica, generaci√≥n de texto, chatbots.
- **An√°lisis de Series Temporales**: Predicci√≥n de mercados financieros, demanda energ√©tica, clima.
- **Reconocimiento de Voz**: Transcripci√≥n y comandos de voz en asistentes virtuales.

#### 3. Redes Generativas Adversariales (GAN) üé®

**Aplicaciones:**
- **Generaci√≥n de Im√°genes y Videos**: Creaci√≥n de arte digital, efectos visuales en pel√≠culas.
- **Aumento de Datos**: Generaci√≥n de datos sint√©ticos para mejorar el entrenamiento de modelos.
- **Restauraci√≥n de Im√°genes**: Mejora de resoluci√≥n, eliminaci√≥n de ruido, restauraci√≥n de im√°genes antiguas.

#### 4. Transformadores üîÑ

**Aplicaciones:**
- **Procesamiento del Lenguaje Natural (NLP)**: Modelos de lenguaje avanzados como GPT, BERT, traducci√≥n autom√°tica.
- **Generaci√≥n de Texto**: Resumen autom√°tico, generaci√≥n de contenido, respuestas autom√°ticas en chats.
- **An√°lisis de Datos**: Clasificaci√≥n de documentos, detecci√≥n de entidades nombradas, an√°lisis de sentimientos.

#### 5. Modelos de Difusi√≥n üå´Ô∏è

**Aplicaciones:**
- **Generaci√≥n de Im√°genes**: Creaci√≥n de im√°genes de alta calidad a partir de descripciones textuales.
- **Simulaci√≥n de Procesos F√≠sicos**: Modelado de fen√≥menos naturales como la difusi√≥n de gases.
- **Dise√±o Gr√°fico**: Creaci√≥n de patrones y texturas para dise√±o digital.

#### 6. Modelos Multimodales üé•üéµüìù

**Aplicaciones:**
- **Sistemas de Recomendaci√≥n**: Recomendaciones personalizadas basadas en m√∫ltiples tipos de datos (texto, im√°genes, audio).
- **An√°lisis de Redes Sociales**: Comprensi√≥n de publicaciones multimedia, an√°lisis de sentimientos.
- **Asistentes Virtuales**: Integraci√≥n de voz, texto e im√°genes para interacci√≥n m√°s natural y completa.


### Recursos para Explorar M√°s:


- **[The GAN Zoo](https://github.com/hindupuravinash/the-gan-zoo)** - Una colecci√≥n de diferentes tipos de GANs.
- **[Attention is All You Need](https://arxiv.org/abs/1706.03762)** - El art√≠culo seminal sobre transformadores.
- **[Explicaci√≥n Completa: Attention is All You Need](https://youtu.be/as2FFM3c6mI?si=_pNuRFCEHHYsizro)** - Un video detallado explicando los transformadores.

---

# D√≠a5
---
## Redes Neuronales Artificiales (ANNs)  üß†

¬°Hola a todos! En el quinto d√≠a de nuestra traves√≠a de 100 d√≠as en el mundo de la Inteligencia Artificial, exploraremos la estructura b√°sica de las Redes Neuronales Artificiales (ANNs) y entenderemos c√≥mo funcionan sus capas neuronales. üåü

### ¬øQu√© son las Redes Neuronales Artificiales (ANNs)?

Las Redes Neuronales Artificiales (ANNs) son modelos computacionales inspirados en el funcionamiento del cerebro humano. Est√°n dise√±adas para reconocer patrones y resolver problemas complejos mediante el aprendizaje a partir de datos. üåê

### Estructura B√°sica de una Red Neuronal

Una red neuronal t√≠pica consta de tres tipos de capas:

1. **Capa de Entrada (Input Layer)**: Recibe los datos iniciales.
2. **Capas Ocultas (Hidden Layers)**: Procesan la informaci√≥n recibida de la capa de entrada.
3. **Capa de Salida (Output Layer)**: Genera el resultado final.


#### 1. **Capa de Entrada (Input Layer)**
La capa de entrada es la primera capa de la red neuronal. Cada nodo en esta capa representa una caracter√≠stica del conjunto de datos de entrada. Por ejemplo, en una red que procesa im√°genes, cada nodo podr√≠a representar el valor de un p√≠xel de la imagen.

#### 2. **Capas Ocultas (Hidden Layers)**
Las capas ocultas son las encargadas de realizar la mayor parte del procesamiento de la red. Pueden existir m√∫ltiples capas ocultas, cada una compuesta por m√∫ltiples nodos o "neuronas". Cada neurona en una capa est√° conectada a todas las neuronas de la capa anterior y de la capa siguiente.

##### Funcionamiento de las Capas Ocultas:
- **Pesos y Sesgos (Weights and Biases)**: Cada conexi√≥n entre neuronas tiene un peso asignado que indica la importancia de la entrada correspondiente. Adem√°s, cada neurona tiene un valor de sesgo que ajusta la salida del nodo.
- **Funciones de Activaci√≥n (Activation Functions)**: Despu√©s de que una neurona recibe la entrada ponderada, aplica una funci√≥n de activaci√≥n para introducir no linealidades en el modelo. Las funciones de activaci√≥n comunes incluyen ReLU (Rectified Linear Unit), Sigmoid y Tanh.



#### 3. **Capa de Salida (Output Layer)**
La capa de salida es la √∫ltima capa de la red neuronal y proporciona el resultado final. La estructura de esta capa depende del tipo de tarea que est√© realizando la red. Por ejemplo, en un problema de clasificaci√≥n binaria, la capa de salida podr√≠a tener una sola neurona con una funci√≥n de activaci√≥n Sigmoid.

### ¬øC√≥mo Aprenden las Redes Neuronales?

El aprendizaje en redes neuronales implica ajustar los pesos y los sesgos de la red para minimizar el error en las predicciones. Este proceso se realiza mediante un algoritmo de optimizaci√≥n llamado **Backpropagation** (retropropagaci√≥n), que utiliza el **Gradiente Descendente** para ajustar los pesos de manera iterativa.


### Recursos para Explorar M√°s:

- **[C√≥mo funcionan las redes neuronales](https://youtu.be/CU24iC3grq8?si=9UT2DpOAA1cQ1Ay0)** (Video).
- **[¬øQu√© es una Red Neuronal?](https://youtu.be/jKCQsndqEGQ?si=jNASfwuoQB9tXyle)** - (Video).
- **[Funciones de activaci√≥n a detalle](https://youtu.be/_0wdproot34?si=B27NeiOze7QGGi6K)** - (Video).
- **[Juegue con una red neuronal ](https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=1&seed=0.87931&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false)** - Juegue con una red neuronal aqu√≠ mismo en su navegador.
No te preocupes, no puedes romperlo.
![ANNs](https://github.com/Oliver369X/100DaysOfAI/assets/110129950/6de8c3e3-ea5a-46e0-8fd0-600e794b422d)

![back2](https://github.com/Oliver369X/100DaysOfAI/assets/110129950/2ebfb67d-7af9-49bd-a509-b1d6babf0148)

---

# D√≠a6
---
## Conceptos de Forward y Backward Propagation üß†üîÑ

¬°Hola a todos! Hoy, en el sexto d√≠a de nuestro viaje de 100 d√≠as en el mundo de la Inteligencia Artificial, exploraremos dos conceptos fundamentales para el entrenamiento de redes neuronales: **Forward Propagation** y **Backward Propagation**. Estos procesos son esenciales para que las redes neuronales aprendan de los datos y mejoren su rendimiento. üöÄ

### ¬øQu√© es Forward Propagation?

**Forward Propagation** es el proceso mediante el cual los datos de entrada se transmiten a trav√©s de la red neuronal para generar una salida. Este flujo de informaci√≥n comienza en la capa de entrada, pasa por las capas ocultas y finalmente llega a la capa de salida.

#### Pasos de Forward Propagation:

1. **Entrada**: Los datos de entrada se presentan a la red neuronal.
2. **Ponderaci√≥n**: Cada neurona en la capa de entrada env√≠a sus datos ponderados a cada neurona de la primera capa oculta.
3. **Activaci√≥n**: Las neuronas de la capa oculta calculan una suma ponderada de sus entradas, aplican una funci√≥n de activaci√≥n y transmiten el resultado a la siguiente capa.
4. **Salida**: Este proceso se repite capa por capa hasta que los datos alcanzan la capa de salida, donde se generan las predicciones finales.

### ¬øQu√© es Backward Propagation?

**Backward Propagation** (o retropropagaci√≥n) es el proceso mediante el cual la red neuronal ajusta sus pesos y sesgos para minimizar el error en sus predicciones. Este ajuste se realiza mediante la propagaci√≥n del error desde la capa de salida hacia atr√°s a trav√©s de las capas ocultas, hasta llegar a la capa de entrada.

#### Pasos de Backward Propagation:

1. **C√°lculo del Error**: Se calcula la diferencia entre la salida real de la red y la salida esperada (etiquetas verdaderas).
2. **Propagaci√≥n del Error**: El error se propaga hacia atr√°s a trav√©s de la red. En cada neurona, se calcula el gradiente del error con respecto a sus pesos y sesgos.
3. **Ajuste de Pesos y Sesgos**: Los pesos y sesgos se actualizan utilizando el gradiente calculado y una tasa de aprendizaje, reduciendo as√≠ el error de la red.

### C√≥mo Funcionan Juntos Forward y Backward Propagation

1. **Forward Propagation**: Los datos de entrada se procesan a trav√©s de la red para generar una predicci√≥n.
2. **C√°lculo del Error**: Se compara la predicci√≥n con la etiqueta verdadera para calcular el error.
3. **Backward Propagation**: El error se propaga hacia atr√°s a trav√©s de la red, y los pesos y sesgos se ajustan en consecuencia.
4. **Actualizaci√≥n de Par√°metros**: Los par√°metros de la red se actualizan para reducir el error en futuras predicciones.

### Ejemplo Simplificado

Imaginemos que estamos entrenando una red neuronal para predecir el precio de una casa basado en su tama√±o.

1. **Forward Propagation**:
   - Entrada: Tama√±o de la casa.
   - C√°lculo: La red multiplica el tama√±o por un peso, a√±ade un sesgo y aplica una funci√≥n de activaci√≥n.
   - Salida: Predicci√≥n del precio de la casa.

2. **C√°lculo del Error**:
   - Comparamos la predicci√≥n con el precio real y calculamos el error.

3. **Backward Propagation**:
   - Propagamos el error hacia atr√°s a trav√©s de la red, calculando el gradiente del error con respecto a cada peso y sesgo.
   - Ajustamos los pesos y sesgos para minimizar el error en futuras predicciones.


### Recursos para Explorar M√°s:

- **[Redes Neuronales (forward propagation y backpropagation)](https://youtu.be/A9jZflhT2R0?si=uQj8Xw1xa2_O1kDO)** -Explicacion matematica(Video).
- **[Las Matem√°ticas de Backpropagation | DotCSV](https://youtu.be/M5QHwkkHgAA?si=ZiX3Gp9I25liaNFq)** - Explicacion matematica(Video).

---

# D√≠a7

---
## Conceptos de Coste y Funciones de P√©rdida üí°üìâ

¬°Hola a todos! Hoy, en el s√©ptimo d√≠a de nuestro reto #100DaysOfAI, exploraremos dos conceptos fundamentales para el entrenamiento de redes neuronales: **coste** y **funciones de p√©rdida**. Estos conceptos son esenciales para evaluar el rendimiento de nuestros modelos y guiar el proceso de aprendizaje. üöÄ

### ¬øQu√© es el Coste?

El **coste** se refiere a la medida de lo mal que un modelo de red neuronal est√° realizando sus predicciones en comparaci√≥n con los valores reales. En otras palabras, es una representaci√≥n cuantitativa del error del modelo. Cuanto menor sea el coste, mejor ser√° el rendimiento del modelo.

### ¬øQu√© es una Funci√≥n de P√©rdida?

Una **funci√≥n de p√©rdida** es una funci√≥n matem√°tica que mide la discrepancia entre las predicciones del modelo y los valores reales. Durante el entrenamiento, el objetivo es minimizar esta funci√≥n de p√©rdida para mejorar la precisi√≥n del modelo. 

### Tipos Comunes de Funciones de P√©rdida:

1. **Error Cuadr√°tico Medio (Mean Squared Error, MSE)**:

2. **Error Absoluto Medio (Mean Absolute Error, MAE)**:


3. **Entrop√≠a Cruzada (Cross-Entropy)**:


### Relaci√≥n entre Coste y Funci√≥n de P√©rdida:

- **Coste Total**: La funci√≥n de p√©rdida calcula el error para una sola instancia de datos, mientras que el coste total (tambi√©n conocido como funci√≥n de coste o funci√≥n de error) es la media de las p√©rdidas para todo el conjunto de entrenamiento.
- **Optimizaci√≥n**: Durante el entrenamiento, el algoritmo de optimizaci√≥n ajusta los pesos de la red neuronal para minimizar el coste total. Esto se realiza t√≠picamente mediante un algoritmo de optimizaci√≥n como el gradiente descendente.

### Importancia en el Entrenamiento

1. **Evaluaci√≥n del Modelo**: Las funciones de p√©rdida nos permiten evaluar cu√°n bien o mal est√° desempe√±√°ndose el modelo.
2. **Gu√≠a para la Optimizaci√≥n**: Proveen la se√±al que gu√≠a el proceso de optimizaci√≥n durante el entrenamiento. Sin una funci√≥n de p√©rdida, no podr√≠amos ajustar los pesos de manera efectiva.
3. **Selecci√≥n de Modelos**: Diferentes problemas pueden requerir diferentes funciones de p√©rdida. Elegir la funci√≥n correcta es crucial para el √©xito del modelo.


### Recursos para Explorar M√°s:

- **[3Blue1Brown's YouTube Series on Neural Networks](https://youtu.be/mwHiaTrQOiI?si=j_a-9WxP_1um9YVc)** - Una serie de videos educativos que visualizan estos procesos de manera intuitiva.

---

# D√≠a8

---
## Algoritmos de Optimizaci√≥n  üöÄüìà

¬°Hola a todos! En el d√≠a 8 de nuestro reto #100DaysOfAI, vamos a profundizar en los **algoritmos de optimizaci√≥n avanzados**. Estos algoritmos son esenciales para mejorar el rendimiento y la eficiencia de los modelos de aprendizaje profundo. ¬°Vamos a explorarlos juntos! üåü

### ¬øQu√© es la Optimizaci√≥n?

La **optimizaci√≥n** en el contexto del aprendizaje profundo se refiere al proceso de ajustar los par√°metros del modelo (como los pesos de las redes neuronales) para minimizar la funci√≥n de p√©rdida. Este proceso es crucial para que el modelo pueda aprender de los datos y hacer predicciones precisas.

### Algoritmos de Optimizaci√≥n Comunes

1. **Gradiente Descendente Estoc√°stico (SGD)**:
   - **Descripci√≥n**: En lugar de utilizar todo el conjunto de datos para calcular los gradientes, el SGD actualiza los par√°metros del modelo usando un solo ejemplo de entrenamiento a la vez.
   - **Ventaja**: Es m√°s r√°pido y puede manejar grandes conjuntos de datos.

2. **Gradiente Descendente por Minilotes (Mini-batch Gradient Descent)**:
   - **Descripci√≥n**: Combina los enfoques de SGD y del gradiente descendente de lote completo, actualizando los par√°metros utilizando un peque√±o subconjunto (mini-lote) de los datos de entrenamiento.
   - **Ventaja**: Equilibra la estabilidad del gradiente descendente de lote completo y la rapidez del SGD.

### Algoritmos de Optimizaci√≥n Avanzados

1. **Momentum**:
   - **Descripci√≥n**: Agrega una fracci√≥n del gradiente anterior al gradiente actual para acelerar la convergencia y evitar quedarse atrapado en m√≠nimos locales.
   - **Ventaja**: Mejora la velocidad y estabilidad del SGD.
  

2. **RMSprop**:
   - **Descripci√≥n**: Divide la tasa de aprendizaje por una media m√≥vil de la magnitud de los gradientes recientes. Esto ayuda a mantener una tasa de aprendizaje adecuada y evita oscilaciones.
   - **Ventaja**: Mantiene una tasa de aprendizaje adaptativa.
  

3. **Adam (Adaptive Moment Estimation)**:
   - **Descripci√≥n**: Combina las ideas de Momentum y RMSprop. Utiliza medias m√≥viles de los gradientes y sus cuadrados, adaptando as√≠ la tasa de aprendizaje para cada par√°metro.
   - **Ventaja**: Convergencia r√°pida y robusta.
  

4. **AdaGrad**:
   - **Descripci√≥n**: Ajusta la tasa de aprendizaje para cada par√°metro en funci√≥n de los gradientes acumulados pasados. 
   - **Ventaja**: Beneficioso para caracter√≠sticas raras y evita el ajuste excesivo en caracter√≠sticas comunes.
   
### Comparaci√≥n de Algoritmos

- **SGD**: Simple y eficiente para grandes conjuntos de datos, pero puede ser ruidoso.
- **Momentum**: Acelera el SGD y suaviza la convergencia.
- **RMSprop**: Adapta la tasa de aprendizaje, √∫til para problemas con tasas de aprendizaje inestables.
- **Adam**: Combina las ventajas de Momentum y RMSprop, ampliamente utilizado.
- **AdaGrad**: Ajusta la tasa de aprendizaje para cada par√°metro, √∫til para datos dispersos.


### Recursos para Explorar M√°s:

- **[Adam - A Method for Stochastic Optimization](https://arxiv.org/abs/1412.6980)** - El art√≠culo original que introduce Adam.
- **[Algoritmos de Optimizaci√≥n ](https://youtu.be/1GFu3nOya4c?si=v3jnhocKnb_R0Xw_)** - Explicacion completa (Video).


---

# D√≠a9
---
## Overfitting y T√©cnicas de Regularizaci√≥n üß†üîç

¬°Hola a todos! En el d√≠a 9 de nuestro desaf√≠o #100DaysOfAI, vamos a sumergirnos en el concepto de **overfitting** y las t√©cnicas de **regularizaci√≥n**. Estas son herramientas fundamentales para mejorar la capacidad predictiva y la generalizaci√≥n de nuestros modelos de aprendizaje profundo. ¬°Vamos a explorarlas juntos! üìâüìö

### ¬øQu√© es el Overfitting?

El **overfitting** ocurre cuando nuestro modelo se ajusta demasiado bien a los datos de entrenamiento, capturando no solo la se√±al real sino tambi√©n el ruido. Como resultado, el modelo puede tener un rendimiento deficiente en datos nuevos y no vistos, lo que lleva a una baja capacidad de generalizaci√≥n.

### T√©cnicas de Regularizaci√≥n

1. **Regularizaci√≥n L1 y L2**:
   - **Descripci√≥n**: Agrega un t√©rmino de penalizaci√≥n a la funci√≥n de p√©rdida que es proporcional a la norma L1 o L2 de los pesos del modelo.
   - **Ventaja**: Ayuda a prevenir el overfitting al penalizar los pesos grandes.

2. **Dropout**:
   - **Descripci√≥n**: Aleatoriamente "apaga" una fracci√≥n de las neuronas durante el entrenamiento, lo que obliga al modelo a aprender caracter√≠sticas m√°s robustas y reduce la dependencia entre las neuronas.
   - **Ventaja**: Act√∫a como una forma de regularizaci√≥n al evitar la coadaptaci√≥n de las neuronas.

3. **Data Augmentation**:
   - **Descripci√≥n**: Aumenta el tama√±o del conjunto de datos de entrenamiento aplicando transformaciones como rotaciones, traslaciones y zoom a las im√°genes originales.
   - **Ventaja**: Ayuda a diversificar el conjunto de datos de entrenamiento y a mejorar la generalizaci√≥n del modelo.

4. **Early Stopping**:
   - **Descripci√≥n**: Detiene el entrenamiento del modelo cuando el rendimiento en un conjunto de datos de validaci√≥n deja de mejorar.
   - **Ventaja**: Evita el sobreajuste al detener el entrenamiento antes de que el modelo comience a sobreajustarse a los datos de entrenamiento.

### Aplicaci√≥n en la Pr√°ctica

Para aplicar estas t√©cnicas de regularizaci√≥n en nuestros modelos, debemos ajustar los hiperpar√°metros adecuados y experimentar con diferentes configuraciones para encontrar el equilibrio √≥ptimo entre la capacidad de ajuste y la generalizaci√≥n.

### Recursos para Explorar M√°s:

- **[Overfitting ](https://youtube.com/playlist?list=PLWP2CHQigyUSw1TJkOdAxzBC0BtKrYAnz&si=InFqmXxk1iRgX611)** - Playlists de underfitting y overfitting.
- **[Dropout: A Simple Way to Prevent Neural Networks from Overfitting](https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf)** - El art√≠culo seminal que introduce la t√©cnica de dropout.
- **[T√©cnicas de Regularizaci√≥n](https://youtu.be/qa9M4NBV9Lk?si=G09xw9uQaTsmwmY4)** - Explicaion practica.


---

# D√≠a10
---
## Construyendo una Red Neuronal desde Cero: Clasificaci√≥n de Flores Iris
### Introducci√≥n al Problema y Objetivos

En esta pr√°ctica, vamos a implementar una red neuronal simple desde cero para resolver el problema de clasificaci√≥n de flores Iris. Este es un problema cl√°sico en el aprendizaje autom√°tico y es perfecto para entender los fundamentos de las redes neuronales.

**Objetivo:** Crear una red neuronal que pueda clasificar correctamente las flores Iris en sus tres especies (setosa, versicolor, virginica) bas√°ndose en cuatro caracter√≠sticas: longitud del s√©palo, ancho del s√©palo, longitud del p√©talo y ancho del p√©talo.

**¬øPor qu√© usar redes neuronales?** Las redes neuronales son excelentes para encontrar patrones complejos en los datos. En este caso, pueden aprender las relaciones no lineales entre las caracter√≠sticas de las flores y sus especies, permitiendo una clasificaci√≥n precisa.

---

## Importaci√≥n de Librer√≠as

Primero, importaremos las librer√≠as necesarias para nuestro proyecto.

```python
import numpy as np
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
import matplotlib.pyplot as plt
```

Explicaci√≥n:
- `numpy`: Para operaciones num√©ricas eficientes.
- `sklearn.datasets`: Para cargar el conjunto de datos Iris.
- `sklearn.model_selection`: Para dividir nuestros datos en conjuntos de entrenamiento y prueba.
- `sklearn.preprocessing`: Para codificar nuestras etiquetas.
- `matplotlib.pyplot`: Para visualizar nuestros resultados.

---

## Carga y Preparaci√≥n del Conjunto de Datos

El conjunto de datos Iris es un conjunto cl√°sico en aprendizaje autom√°tico. Contiene 150 muestras de flores Iris, con 50 muestras de cada una de las tres especies.

```python
# Cargar el conjunto de datos Iris
iris = load_iris()
X = iris.data
y = iris.target.reshape(-1, 1)

# One-hot encoding para las etiquetas
encoder = OneHotEncoder(sparse=False)
y = encoder.fit_transform(y)

# Dividir datos en entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("Forma de X_train:", X_train.shape)
print("Forma de y_train:", y_train.shape)
print("Forma de X_test:", X_test.shape)
print("Forma de y_test:", y_test.shape)
```

Explicaci√≥n:
- Cargamos el conjunto de datos Iris.
- Aplicamos one-hot encoding a las etiquetas para convertirlas en un formato adecuado para la red neuronal.
- Dividimos los datos en conjuntos de entrenamiento (80%) y prueba (20%).
- Imprimimos las formas de nuestros conjuntos de datos para verificar.

---

## Implementaci√≥n de la Red Neuronal

Ahora, implementaremos nuestra clase de red neuronal simple.

```python
class SimpleNeuralNetwork:
    def __init__(self, input_size, hidden_size, output_size):
        self.W1 = np.random.randn(input_size, hidden_size) * 0.01
        self.b1 = np.zeros((1, hidden_size))
        self.W2 = np.random.randn(hidden_size, output_size) * 0.01
        self.b2 = np.zeros((1, output_size))

    def sigmoid(self, x):
        return 1 / (1 + np.exp(-x))

    def softmax(self, x):
        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))
        return exp_x / np.sum(exp_x, axis=1, keepdims=True)
```

Explicaci√≥n:
- Inicializamos los pesos (`W1`, `W2`) y sesgos (`b1`, `b2`) de nuestra red.
- Implementamos la funci√≥n de activaci√≥n sigmoid para la capa oculta.
- Implementamos la funci√≥n softmax para la capa de salida, que nos dar√° probabilidades para cada clase.

---

## Forward Propagation

Implementamos el paso hacia adelante (forward propagation) de nuestra red.

```python
def forward(self, X):
    self.z1 = np.dot(X, self.W1) + self.b1
    self.a1 = self.sigmoid(self.z1)
    self.z2 = np.dot(self.a1, self.W2) + self.b2
    self.a2 = self.softmax(self.z2)
    return self.a2
```

Explicaci√≥n:
- Calculamos la salida de la capa oculta (`z1`) y aplicamos la funci√≥n sigmoid (`a1`).
- Calculamos la salida de la capa final (`z2`) y aplicamos softmax (`a2`).
- Retornamos la salida final, que son las probabilidades para cada clase.

---

## Funci√≥n de P√©rdida

Implementamos la funci√≥n de p√©rdida de entrop√≠a cruzada.

```python
def cross_entropy_loss(self, y_true, y_pred):
    m = y_true.shape[0]
    log_likelihood = -np.log(y_pred[range(m), y_true.argmax(axis=1)])
    loss = np.sum(log_likelihood) / m
    return loss
```

Explicaci√≥n:
- Calculamos la p√©rdida de entrop√≠a cruzada entre las etiquetas verdaderas y las predicciones.
- Esta funci√≥n mide qu√© tan bien nuestras predicciones se ajustan a las etiquetas reales.

---

## Backward Propagation

Implementamos la retropropagaci√≥n (backward propagation) para actualizar los pesos.

```python
def backward(self, X, y, learning_rate):
    m = X.shape[0]
    
    dZ2 = self.a2 - y
    dW2 = np.dot(self.a1.T, dZ2) / m
    db2 = np.sum(dZ2, axis=0, keepdims=True) / m
    
    dZ1 = np.dot(dZ2, self.W2.T) * (self.a1 * (1 - self.a1))
    dW1 = np.dot(X.T, dZ1) / m
    db1 = np.sum(dZ1, axis=0, keepdims=True) / m
    
    self.W2 -= learning_rate * dW2
    self.b2 -= learning_rate * db2
    self.W1 -= learning_rate * dW1
    self.b1 -= learning_rate * db1
```

Explicaci√≥n:
- Calculamos los gradientes para cada capa.
- Actualizamos los pesos y sesgos usando estos gradientes y la tasa de aprendizaje.

---

## Entrenamiento

Implementamos el bucle de entrenamiento.

```python
def train(self, X, y, epochs, learning_rate, batch_size):
    losses = []
    for epoch in range(epochs):
        for i in range(0, X.shape[0], batch_size):
            X_batch = X[i:i+batch_size]
            y_batch = y[i:i+batch_size]
            
            y_pred = self.forward(X_batch)
            loss = self.cross_entropy_loss(y_batch, y_pred)
            self.backward(X_batch, y_batch, learning_rate)
            
        if epoch % 100 == 0:
            losses.append(loss)
            print(f"Epoch {epoch}, Loss: {loss}")
    return losses
```

Explicaci√≥n:
- Entrenamos la red durante un n√∫mero especificado de √©pocas.
- Usamos mini-batch gradient descent para actualizar los pesos.
- Registramos la p√©rdida cada 100 √©pocas para monitorear el progreso.

---

## Evaluaci√≥n

Implementamos funciones para hacer predicciones y calcular la precisi√≥n.

```python
def predict(self, X):
    return np.argmax(self.forward(X), axis=1)

def accuracy(self, X, y):
    predictions = self.predict(X)
    return np.mean(predictions == np.argmax(y, axis=1))
```

Explicaci√≥n:
- `predict`: Hace predicciones para nuevos datos.
- `accuracy`: Calcula la precisi√≥n de nuestras predicciones.

---

## Entrenamiento y Evaluaci√≥n del Modelo

Ahora, entrenamos nuestro modelo y evaluamos su rendimiento.

```python
# Crear y entrenar el modelo
model = SimpleNeuralNetwork(input_size=4, hidden_size=10, output_size=3)
losses = model.train(X_train, y_train, epochs=1000, learning_rate=0.1, batch_size=32)

# Evaluar el modelo
train_accuracy = model.accuracy(X_train, y_train)
test_accuracy = model.accuracy(X_test, y_test)

print(f"Precisi√≥n en entrenamiento: {train_accuracy:.4f}")
print(f"Precisi√≥n en prueba: {test_accuracy:.4f}")
```

Explicaci√≥n:
- Creamos una instancia de nuestra red neuronal.
- Entrenamos el modelo durante 1000 √©pocas.
- Evaluamos la precisi√≥n en los conjuntos de entrenamiento y prueba.

---

## Visualizaci√≥n de Resultados

Finalmente, visualizamos c√≥mo la p√©rdida cambia durante el entrenamiento.

```python
plt.plot(range(0, 1000, 100), losses)
plt.xlabel('√âpocas')
plt.ylabel('P√©rdida')
plt.title('P√©rdida durante el entrenamiento')
plt.show()
```

Explicaci√≥n:
- Graficamos la p√©rdida a lo largo de las √©pocas de entrenamiento.
- Esto nos ayuda a visualizar c√≥mo el modelo aprende con el tiempo.


### Recursos para Explorar M√°s:

- **[An√°lisis exploratorio de datos del conjunto de datos Iris](https://youtu.be/yu4SYEYkZ6U?si=oOb1DEuG5GcS-f4e)** MasterClass (video)
- **[Analisis Exploratorio de Datos dataset Iris](https://www.kaggle.com/code/joeportilla/analisis-exploratorio-de-datos-dataset-iris)** - Notebook Kaggle.


---

# D√≠a11
# D√≠a12
# D√≠a13
# D√≠a14
# D√≠a15
# D√≠a16
# D√≠a17
# D√≠a18
# D√≠a19
# D√≠a20
# D√≠a21
# D√≠a22
# D√≠a23
# D√≠a24
# D√≠a25
# D√≠a26
# D√≠a27
# D√≠a28
# D√≠a29
# D√≠a30
# D√≠a31
# D√≠a32
# D√≠a33
# D√≠a34
# D√≠a35
# D√≠a36
# D√≠a37
# D√≠a38
# D√≠a39
# D√≠a40
# D√≠a41
# D√≠a42
# D√≠a43
# D√≠a44
# D√≠a45
# D√≠a46
# D√≠a47
# D√≠a48
# D√≠a49
# D√≠a50
# D√≠a51
# D√≠a52
# D√≠a53
# D√≠a54
# D√≠a55
# D√≠a56
# D√≠a57
# D√≠a58
# D√≠a59
# D√≠a60
# D√≠a61
# D√≠a62
# D√≠a63
# D√≠a64
# D√≠a65
# D√≠a66
# D√≠a67
# D√≠a68
# D√≠a69
# D√≠a70
# D√≠a71
# D√≠a72
# D√≠a73
# D√≠a74
# D√≠a75
# D√≠a76
# D√≠a77
# D√≠a78
# D√≠a79
# D√≠a80
# D√≠a81
# D√≠a82
# D√≠a83
# D√≠a84
# D√≠a85
# D√≠a86
# D√≠a87
# D√≠a88
# D√≠a89
# D√≠a90
# D√≠a91
# D√≠a92
# D√≠a93
# D√≠a94
# D√≠a95
# D√≠a96
# D√≠a97
# D√≠a98
# D√≠a99
# D√≠a100
